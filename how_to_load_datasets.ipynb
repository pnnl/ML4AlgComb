{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ccfe58-11bb-4efe-b9bd-f94eaa8404e4",
   "metadata": {},
   "source": [
    "## How to load the different datasets in ML4AlgComb\n",
    "\n",
    "This notebook shows how to load the datasets and how to create dataloaders that you can use for model training. \n",
    "\n",
    "Author: Helen Jenne\n",
    "Last updated: 08/11/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83eaa162-e11c-46a8-88ee-968719c5b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5fab1c6-fe1a-4981-a395-fbc36c75eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_datasets import get_dataset\n",
    "from dataloaders import CombDataModule, OneHotDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407e3f0-a42a-4b38-8f39-0346ea17acb4",
   "metadata": {},
   "source": [
    "FOLDER is the filepath to the folder containing the various datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4eca861-4f14-43b9-a881-3de6b496bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"/qfs/projects/giant_isopod/data/davis_upload/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d141a3-3f4d-42c9-92d2-6371c3b87312",
   "metadata": {},
   "source": [
    "## Grassmannian cluster algebras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e6d0e6-c26d-4b43-b94b-ed1f40a23004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 148658 examples\n",
      "Test set has 37164 examples\n",
      "Inputs are sequences of length 12, with 13 tokens, which represent 3x4 SSYT\n",
      "There are 2 classes. SSYT that index a valid cluster variable are labeled 1 and SSYT that do not are labeled 0.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"grassmannian_cluster_algebras\"\n",
    "N = 12\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3876b9a-0480-432c-81d8-3b93d452cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92911"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in y_train if x ==1] + [x for x in y_test if x ==1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1683ee4-bcac-481f-85eb-6079e30b8154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92911"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in y_train if x ==0] + [x for x in y_test if x ==0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b2d66a0-e6b0-43d7-bbc0-a41a3647b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c576fed-9bca-49d4-a810-d8c46e9f1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  5.,  7.,  4.,  4.,  8., 10.,  5., 11., 12., 12.],\n",
      "        [ 1.,  2.,  5.,  6.,  5.,  6.,  7.,  7.,  8.,  8.,  9., 11.],\n",
      "        [ 2.,  4.,  6.,  7.,  3.,  5., 10., 11.,  7.,  9., 11., 12.],\n",
      "        [ 1.,  2.,  2.,  2.,  2.,  6.,  6.,  9.,  7.,  9., 11., 11.],\n",
      "        [ 1.,  1.,  6.,  9.,  4.,  7.,  7., 10.,  9., 10., 10., 12.],\n",
      "        [ 6.,  6.,  6.,  6.,  8.,  9., 10., 11., 11., 11., 12., 12.],\n",
      "        [ 1.,  2.,  3.,  4.,  2.,  3.,  7.,  8.,  5.,  6.,  8., 10.],\n",
      "        [ 1.,  2.,  3.,  6.,  4.,  4.,  8.,  9.,  7.,  7., 10., 11.],\n",
      "        [ 2.,  2.,  3.,  9.,  5.,  6.,  8., 11.,  9., 10., 11., 12.],\n",
      "        [ 1.,  3.,  4.,  5.,  5.,  8.,  8., 11.,  6., 11., 12., 12.],\n",
      "        [ 1.,  2.,  2.,  7.,  2.,  6.,  8., 10.,  7.,  8., 12., 12.],\n",
      "        [ 1.,  4.,  6.,  7.,  6.,  6.,  9.,  9.,  7.,  8., 10., 12.],\n",
      "        [ 1.,  3.,  4.,  4.,  3.,  6.,  7.,  9.,  5.,  9., 10., 12.],\n",
      "        [ 1.,  2.,  6.,  7.,  3.,  4.,  9.,  9.,  5.,  5., 10., 10.],\n",
      "        [ 1.,  2.,  2.,  3.,  3.,  4.,  6.,  6.,  7.,  9., 10., 12.],\n",
      "        [ 2.,  4.,  6.,  8.,  5.,  6.,  7., 11.,  9., 10., 10., 12.],\n",
      "        [ 1.,  4.,  5.,  6.,  3.,  8.,  8.,  8.,  7.,  9., 11., 12.],\n",
      "        [ 1.,  1.,  5.,  8.,  6.,  7.,  9., 10.,  8.,  9., 11., 11.],\n",
      "        [ 1.,  2.,  5.,  5.,  3.,  6.,  6.,  7.,  5.,  8., 11., 12.],\n",
      "        [ 2.,  4.,  4., 10.,  6.,  7., 11., 11.,  8.,  9., 12., 12.],\n",
      "        [ 1.,  3.,  3.,  4.,  5.,  6.,  6.,  7.,  7.,  9., 11., 12.],\n",
      "        [ 2.,  3.,  3.,  7.,  3.,  6.,  7.,  8.,  8., 10., 11., 11.],\n",
      "        [ 1.,  3.,  4.,  4.,  2.,  5.,  6.,  7.,  5., 10., 10., 11.],\n",
      "        [ 1.,  1.,  1.,  4.,  5.,  5.,  8., 11.,  9.,  9., 11., 12.],\n",
      "        [ 2.,  3.,  4.,  5.,  3.,  8.,  9.,  9.,  5., 10., 11., 12.],\n",
      "        [ 1.,  3.,  5.,  7.,  2.,  6.,  9., 10.,  8.,  9., 11., 12.],\n",
      "        [ 1.,  2.,  4.,  4.,  3.,  8.,  9., 10.,  5., 11., 12., 12.],\n",
      "        [ 1.,  3.,  5., 10.,  6.,  8.,  8., 11.,  7., 10., 10., 12.],\n",
      "        [ 1.,  1.,  1.,  3.,  2.,  2.,  3.,  9.,  3.,  4.,  8., 11.],\n",
      "        [ 1.,  1.,  1.,  2.,  3.,  5.,  5.,  5.,  7.,  7., 10., 11.],\n",
      "        [ 2.,  3.,  3.,  8.,  3.,  7., 10., 11.,  8., 11., 12., 12.],\n",
      "        [ 1.,  4.,  5.,  9.,  7.,  7., 10., 10.,  8., 10., 11., 11.]])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f4343-f68f-4a92-9c88-d73eac4953e8",
   "metadata": {},
   "source": [
    "## KL polynomial coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7954d7-1a46-4a21-8215-e891da548c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 67699 examples\n",
      "Test set has 16925 examples\n",
      "Inputs are sequences of length 16, representing two permutations on the letters 0 through 7\n",
      "There are 10 classes, which each represent the fifth coefficient in the polynomial.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"kl_polynomial\"\n",
    "N = 8 #N = 8, 9 are supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88aa2b32-e33f-4901-a6b0-a1dacd0f2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "662d682b-c27b-4dfe-82dc-55c7aa4b6dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 0., 7., 5., 4., 1., 6., 3., 7., 5., 6., 0., 4., 2., 3., 1.],\n",
      "        [1., 0., 3., 2., 5., 7., 6., 4., 7., 5., 6., 0., 3., 4., 1., 2.],\n",
      "        [2., 5., 0., 1., 3., 7., 4., 6., 5., 7., 2., 3., 4., 6., 0., 1.],\n",
      "        [3., 0., 2., 5., 1., 6., 7., 4., 5., 3., 6., 7., 0., 2., 4., 1.],\n",
      "        [1., 0., 3., 5., 2., 4., 7., 6., 3., 1., 2., 7., 0., 5., 6., 4.],\n",
      "        [1., 4., 2., 6., 3., 0., 7., 5., 6., 7., 4., 5., 1., 2., 3., 0.],\n",
      "        [1., 0., 5., 4., 3., 2., 7., 6., 5., 1., 4., 7., 3., 2., 6., 0.],\n",
      "        [1., 0., 3., 6., 5., 4., 2., 7., 3., 1., 6., 7., 4., 2., 0., 5.],\n",
      "        [1., 4., 0., 3., 7., 2., 6., 5., 4., 7., 1., 5., 6., 2., 3., 0.],\n",
      "        [0., 2., 3., 1., 4., 6., 5., 7., 2., 6., 7., 3., 4., 5., 0., 1.],\n",
      "        [1., 0., 3., 2., 5., 6., 7., 4., 5., 6., 7., 1., 2., 3., 4., 0.],\n",
      "        [2., 5., 4., 3., 0., 7., 1., 6., 4., 7., 5., 2., 3., 6., 0., 1.],\n",
      "        [1., 6., 5., 0., 3., 2., 7., 4., 6., 7., 3., 1., 5., 2., 4., 0.],\n",
      "        [0., 5., 1., 4., 3., 2., 7., 6., 5., 6., 4., 7., 3., 0., 1., 2.],\n",
      "        [1., 0., 4., 6., 3., 7., 5., 2., 6., 4., 5., 7., 1., 3., 2., 0.],\n",
      "        [0., 1., 3., 2., 6., 4., 7., 5., 3., 4., 6., 5., 7., 0., 1., 2.],\n",
      "        [4., 3., 0., 7., 2., 1., 6., 5., 6., 7., 2., 4., 3., 0., 5., 1.],\n",
      "        [5., 1., 0., 4., 3., 2., 7., 6., 7., 4., 1., 3., 5., 2., 6., 0.],\n",
      "        [5., 0., 7., 2., 1., 6., 4., 3., 7., 5., 6., 4., 0., 2., 3., 1.],\n",
      "        [5., 4., 0., 3., 1., 7., 2., 6., 7., 5., 3., 4., 0., 6., 1., 2.],\n",
      "        [2., 6., 1., 0., 5., 7., 4., 3., 6., 7., 5., 2., 3., 4., 0., 1.],\n",
      "        [2., 6., 4., 0., 5., 3., 1., 7., 6., 7., 4., 2., 5., 3., 0., 1.],\n",
      "        [1., 0., 6., 4., 3., 2., 7., 5., 4., 6., 7., 5., 0., 1., 2., 3.],\n",
      "        [0., 3., 1., 4., 2., 5., 7., 6., 3., 4., 0., 7., 1., 5., 6., 2.],\n",
      "        [1., 0., 6., 4., 2., 5., 7., 3., 4., 6., 7., 1., 2., 3., 5., 0.],\n",
      "        [2., 1., 4., 0., 7., 6., 5., 3., 7., 4., 6., 2., 5., 0., 3., 1.],\n",
      "        [3., 0., 6., 5., 2., 1., 7., 4., 6., 3., 7., 4., 5., 0., 2., 1.],\n",
      "        [2., 1., 6., 0., 5., 3., 7., 4., 6., 5., 7., 2., 3., 0., 4., 1.],\n",
      "        [0., 2., 5., 4., 6., 1., 7., 3., 5., 6., 7., 0., 2., 3., 4., 1.],\n",
      "        [2., 1., 5., 0., 7., 6., 4., 3., 5., 2., 7., 4., 6., 3., 0., 1.],\n",
      "        [2., 4., 1., 3., 0., 6., 5., 7., 6., 7., 2., 4., 1., 5., 0., 3.],\n",
      "        [3., 2., 1., 0., 6., 4., 5., 7., 6., 3., 7., 4., 5., 0., 1., 2.]])\n",
      "tensor([0, 9, 2, 0, 0, 1, 0, 0, 6, 2, 5, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        5, 0, 0, 8, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a103af5-e014-4fc6-b286-75d2b1708ead",
   "metadata": {},
   "source": [
    "## Lattice path posets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5236565-5534-4956-909d-d57ed097861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 497369 examples\n",
      "Test set has 124369 examples\n",
      "Inputs are two concatenated binary sequences represented a lattice path and its cover. The input for n=13 is length 75.\n",
      "There are 2 classes. Lagrange covers are labeled 0, matching covers are labeled 1.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"lattice_path\"\n",
    "N = 13 #N = 10, 11, 12, 13 supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94bab4e9-9f5e-451c-9a16-bd323f21112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656405109547752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is not a balanced dataset\n",
    "len([x for x in y_train if x ==0] + [x for x in y_test if x ==0] )/(len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e3218d2f-db87-40b9-9765-66737abf341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7b12cc1e-fbe4-4997-ac7b-cfa59bd23157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 0.]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde59bc0-7658-49b9-a6fd-20dca5956a7d",
   "metadata": {},
   "source": [
    "## mHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96d934c2-607d-4022-a2d8-9e1166523c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 2627172 examples\n",
      "Test set has 656791 examples\n",
      "Input sequences are permutations represented by their inversion sequence, which is a binary sequence of length (11 choose 2)= 55.\n",
      "There are 5 classes; classes that contained less than 0.01% of the data were filtered.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"mheight\"\n",
    "N = 11 #N = 10, 11, 12 are supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdfac3a4-a322-491b-be63-ac4e7bf77000",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "738c912c-6512-4a4a-91bc-355bf0944b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2b98d-33f4-421a-a4e3-349fa22032e7",
   "metadata": {},
   "source": [
    "## Quiver mutation equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d3f833-755f-4f5b-ac8b-8f66e206b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 163795 examples\n",
      "Test set has 40944 examples\n",
      "Input sequences of length 120 are flattened adjacency matrices with entries 0 through 5\n",
      "There are 7 classes: A_11: 0, BD_11: 1, D_11: 2, BE_11: 3, BB_11: 4, E_11: 5, DE_11: 6\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"quiver\"\n",
    "N = 11 #This is the only value of N supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3360a4b7-7e69-4e66-9c63-6e168876eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07289280498586005\n",
      "0.14439359379502684\n",
      "0.15661891481349424\n",
      "0.13806846765882416\n",
      "0.16734476577496227\n",
      "0.1770400363389486\n",
      "0.14364141663288382\n"
     ]
    }
   ],
   "source": [
    "#This is not a balanced dataset\n",
    "for i in range(7):\n",
    "    print( (len([x for x in y_train if x ==i]) + len([x for x in y_test if x ==i]) ) /(len(y_train) + len(y_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5dcdcfa3-cedc-4268-8449-ed5ee67dbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea457c26-5c4a-4cde-aa56-b147d9061ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.,  ..., 2., 3., 3.],\n",
      "        [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "        [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "        ...,\n",
      "        [2., 2., 2.,  ..., 1., 2., 2.],\n",
      "        [2., 2., 2.,  ..., 2., 3., 2.],\n",
      "        [2., 2., 2.,  ..., 2., 3., 2.]])\n",
      "tensor([1, 1, 4, 4, 5, 1, 3, 4, 3, 3, 6, 5, 4, 5, 4, 1, 3, 2, 4, 6, 6, 4, 2, 3,\n",
      "        1, 1, 5, 3, 6, 5, 0, 5])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb204cf-4b88-473a-b355-d1f6f5661af8",
   "metadata": {},
   "source": [
    "## RSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73d8c40-0c04-4be9-bd46-f19d51ab03e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 2903040 examples\n",
      "Test set has 725760 examples\n",
      "Input sequence is length 66 with entries 0 through 12, representing two concatenated SSYT, padded so that all inputs have the same length.\n",
      "Outputs are binary sequences of length 45. Output is one permutation represented by its inversion sequence.\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "dataset_name = \"rsk\"\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cb87f-72d6-4d3f-9ebe-9f1b2571fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train) + len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6232b215-59c3-470f-84a9-7f0a7a267ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec3abe4d-41df-45ff-b84e-cb3fadc20ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  ..., 10., 10., 10.],\n",
      "        [ 0.,  0.,  0.,  ..., 10., 10., 10.],\n",
      "        [ 0.,  0.,  0.,  ..., 10., 10., 10.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., 10., 10., 10.],\n",
      "        [ 0.,  0.,  0.,  ..., 10., 10., 10.],\n",
      "        [ 0.,  0.,  0.,  ..., 10., 10., 10.]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "         1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 1, 1],\n",
      "        [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "         0, 1, 1, 0],\n",
      "        [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "         1, 0, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "         0, 1, 0, 0],\n",
      "        [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "         1, 0, 0, 1],\n",
      "        [0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "         0, 0, 1, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "         0, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 1, 1],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "         0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11582b2e-5084-4ff8-821e-d1f6ccd43add",
   "metadata": {},
   "source": [
    "## Schubert polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1d61874-ad8d-4956-8bb7-d966c840d56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 85620 examples\n",
      "Test set has 21405 examples\n",
      "Inputs are sequences of length 19, which represent three concatenated permutations on the letters 0 through 9.\n",
      "There are 3 classes, which give the structure constant for the input permutations.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"schubert\"\n",
    "N = 5 #N = 4, 5, 6 are suppored\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a0e9f90-771e-41c0-a03a-b2650993c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N=6 has 6 classes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a502a471-62bd-44fc-832a-9baafecea2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e6188b-aa39-41f9-9862-a3c264aa1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 5., 3., 2., 5., 3., 2., 4., 1., 6., 5., 3., 4., 1., 2., 7., 8.,\n",
      "         9.],\n",
      "        [4., 3., 2., 5., 1., 2., 3., 5., 4., 1., 5., 6., 3., 4., 1., 2., 7., 8.,\n",
      "         9.],\n",
      "        [2., 1., 4., 5., 3., 5., 1., 2., 3., 4., 7., 4., 2., 1., 3., 5., 6., 8.,\n",
      "         9.],\n",
      "        [2., 1., 4., 5., 3., 1., 2., 4., 3., 5., 3., 2., 4., 5., 1., 6., 7., 8.,\n",
      "         9.],\n",
      "        [3., 2., 5., 1., 4., 1., 4., 2., 3., 5., 5., 3., 4., 1., 2., 6., 7., 8.,\n",
      "         9.],\n",
      "        [1., 5., 2., 4., 3., 5., 2., 3., 1., 4., 7., 4., 3., 1., 2., 5., 6., 8.,\n",
      "         9.],\n",
      "        [3., 1., 2., 4., 5., 4., 5., 1., 2., 3., 6., 4., 5., 2., 3., 1., 7., 8.,\n",
      "         9.],\n",
      "        [5., 3., 1., 4., 2., 1., 4., 5., 3., 2., 6., 4., 5., 2., 1., 3., 7., 8.,\n",
      "         9.],\n",
      "        [2., 1., 3., 5., 4., 2., 1., 4., 5., 3., 4., 1., 3., 5., 2., 6., 7., 8.,\n",
      "         9.],\n",
      "        [5., 3., 4., 2., 1., 1., 5., 4., 3., 2., 1., 7., 6., 3., 5., 2., 4., 8.,\n",
      "         9.],\n",
      "        [2., 1., 5., 4., 3., 1., 3., 5., 4., 2., 3., 4., 6., 2., 1., 5., 7., 8.,\n",
      "         9.],\n",
      "        [1., 4., 3., 2., 5., 1., 2., 5., 3., 4., 1., 4., 3., 2., 6., 5., 7., 8.,\n",
      "         9.],\n",
      "        [1., 5., 4., 2., 3., 2., 5., 1., 4., 3., 4., 8., 1., 3., 2., 5., 6., 7.,\n",
      "         9.],\n",
      "        [1., 5., 4., 2., 3., 5., 2., 3., 1., 4., 8., 2., 5., 1., 3., 4., 6., 7.,\n",
      "         9.],\n",
      "        [3., 1., 5., 4., 2., 5., 1., 4., 3., 2., 7., 3., 4., 5., 1., 2., 6., 8.,\n",
      "         9.],\n",
      "        [3., 5., 1., 2., 4., 2., 1., 5., 4., 3., 7., 4., 1., 2., 3., 5., 6., 8.,\n",
      "         9.],\n",
      "        [1., 5., 4., 2., 3., 3., 2., 5., 4., 1., 5., 7., 4., 3., 1., 2., 6., 8.,\n",
      "         9.],\n",
      "        [3., 2., 1., 4., 5., 4., 5., 3., 2., 1., 6., 5., 3., 2., 1., 4., 7., 8.,\n",
      "         9.],\n",
      "        [2., 5., 4., 3., 1., 2., 1., 3., 5., 4., 4., 5., 2., 6., 1., 3., 7., 8.,\n",
      "         9.],\n",
      "        [3., 5., 2., 1., 4., 3., 1., 5., 2., 4., 7., 3., 4., 1., 2., 5., 6., 8.,\n",
      "         9.],\n",
      "        [2., 4., 1., 3., 5., 1., 4., 2., 5., 3., 1., 5., 3., 4., 2., 6., 7., 8.,\n",
      "         9.],\n",
      "        [1., 3., 2., 5., 4., 2., 3., 5., 4., 1., 2., 5., 3., 6., 1., 4., 7., 8.,\n",
      "         9.],\n",
      "        [3., 4., 1., 2., 5., 2., 3., 4., 1., 5., 4., 5., 2., 1., 3., 6., 7., 8.,\n",
      "         9.],\n",
      "        [2., 1., 5., 4., 3., 1., 5., 2., 3., 4., 3., 5., 4., 1., 2., 6., 7., 8.,\n",
      "         9.],\n",
      "        [3., 2., 1., 5., 4., 3., 1., 4., 5., 2., 5., 2., 3., 6., 1., 4., 7., 8.,\n",
      "         9.],\n",
      "        [1., 4., 5., 3., 2., 2., 4., 1., 5., 3., 1., 6., 4., 2., 3., 5., 7., 8.,\n",
      "         9.],\n",
      "        [5., 3., 4., 1., 2., 1., 3., 2., 4., 5., 6., 3., 4., 1., 2., 5., 7., 8.,\n",
      "         9.],\n",
      "        [1., 2., 5., 3., 4., 2., 3., 5., 4., 1., 2., 3., 7., 4., 1., 5., 6., 8.,\n",
      "         9.],\n",
      "        [4., 5., 3., 1., 2., 4., 2., 5., 1., 3., 7., 2., 4., 1., 6., 3., 5., 8.,\n",
      "         9.],\n",
      "        [1., 5., 2., 4., 3., 1., 2., 5., 4., 3., 1., 6., 4., 3., 2., 5., 7., 8.,\n",
      "         9.],\n",
      "        [5., 3., 1., 4., 2., 5., 1., 2., 4., 3., 9., 3., 2., 4., 1., 5., 6., 7.,\n",
      "         8.],\n",
      "        [4., 1., 2., 5., 3., 5., 2., 4., 3., 1., 8., 2., 5., 3., 1., 4., 6., 7.,\n",
      "         9.]])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16926410-8004-4619-aca8-36cde9f75c3e",
   "metadata": {},
   "source": [
    "## Symmetric group character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38864746-e391-43c0-8e4e-fe0a1a8b392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 112630 examples\n",
      "Test set has 28216 examples\n",
      "Inputs are sequences of length 36 with entries 0 through 18, which represent two concatenated integer partitions of n=18.\n",
      "There are 589 classes for n=18.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"symmetric_group_char\"\n",
    "N = 18 #N = 18, 20, 22 supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c001d51-e95a-41f5-b923-36f6af189056",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd48543f-bb83-4e9f-814c-0febdf83b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  5.,  5.,  ...,  0.,  0.,  0.],\n",
      "        [ 5.,  2.,  2.,  ...,  0.,  0.,  0.],\n",
      "        [ 5.,  3.,  2.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 5.,  5.,  3.,  ...,  0.,  0.,  0.],\n",
      "        [ 8.,  7.,  2.,  ...,  0.,  0.,  0.],\n",
      "        [13.,  1.,  1.,  ...,  0.,  0.,  0.]])\n",
      "tensor([293, 294, 299, 295, 294, 294, 292, 294, 318, 348, 290, 293, 296, 249,\n",
      "        294, 294, 294, 304, 302, 292, 294, 294, 294, 294, 294, 300, 297, 299,\n",
      "        434, 294, 294, 280])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "248720de-5aee-4332-aaa5-6fd54efe3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also one-hot encode the data\n",
    "data_module = OneHotDataModule(X_train, y_train, X_test, y_test, num_tokens, batch_size=batch_size_choice)\n",
    "data_module.setup()\n",
    "input_size = input_size*num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12b74ca1-d3e2-4809-856f-c4de7f43f3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([294, 294, 294, 294, 295, 293, 293, 296, 294, 295, 295, 299, 294, 294,\n",
      "        293, 294, 295, 293, 291, 294, 291, 294, 296, 294, 294, 290, 294, 294,\n",
      "        294, 297, 292, 293])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f03326-7a08-4769-a973-bc538a60a7ea",
   "metadata": {},
   "source": [
    "## Weaving patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432622cb-ae86-4ed4-a4da-8557e4996994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 1750 examples\n",
      "Test set has 751 examples\n",
      "Inputs are sequences of length 16 with entries between 0 and 5, representing weaving patterns.\n",
      "There are 2 classes. Weaving patterns are labeled 1, non-weaving patterns are labeled 0.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"weaving\"\n",
    "N = 6 #N = 6, 7, 8 supported\n",
    "X_train, y_train, X_test, y_test, input_size, output_size, num_tokens = get_dataset(data = dataset_name, n = N, folder = FOLDER )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "edb93b18-aa92-4749-922e-79edbcf1aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_choice = 32\n",
    "data_module = CombDataModule(X_train, y_train, X_test, y_test, batch_size=batch_size_choice)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fc6ba10-3062-4532-b071-b85288f355d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3., 3., 2., 3., 4., 4., 3., 2., 3., 3., 2., 3., 2.],\n",
      "        [2., 3., 4., 5., 3., 2., 1., 2., 2., 1., 2., 1., 3., 2., 3., 2.],\n",
      "        [2., 3., 4., 3., 3., 2., 3., 2., 2., 3., 2., 1., 5., 4., 3., 2.],\n",
      "        [2., 3., 2., 3., 3., 2., 1., 2., 2., 1., 2., 3., 3., 4., 3., 2.],\n",
      "        [0., 1., 2., 3., 3., 2., 3., 2., 4., 3., 2., 3., 5., 4., 3., 2.],\n",
      "        [2., 3., 2., 3., 1., 0., 1., 2., 2., 1., 2., 1., 3., 2., 1., 0.],\n",
      "        [0., 1., 2., 3., 3., 4., 3., 4., 2., 3., 4., 3., 3., 4., 3., 2.],\n",
      "        [2., 3., 4., 5., 1., 0., 1., 2., 4., 3., 4., 3., 3., 2., 3., 2.],\n",
      "        [2., 3., 2., 3., 3., 4., 5., 4., 2., 3., 2., 3., 3., 2., 3., 2.],\n",
      "        [2., 3., 2., 3., 3., 2., 1., 2., 2., 1., 2., 1., 3., 2., 3., 2.],\n",
      "        [2., 1., 2., 3., 1., 2., 1., 2., 2., 1., 0., 1., 3., 2., 1., 0.],\n",
      "        [2., 1., 2., 3., 3., 2., 3., 4., 4., 3., 4., 3., 3., 2., 1., 2.],\n",
      "        [2., 3., 2., 3., 1., 2., 3., 2., 2., 3., 4., 3., 5., 4., 3., 2.],\n",
      "        [0., 1., 2., 3., 1., 2., 3., 4., 2., 1., 2., 3., 3., 2., 1., 0.],\n",
      "        [2., 3., 4., 3., 3., 2., 3., 2., 2., 1., 2., 1., 5., 4., 3., 2.],\n",
      "        [2., 3., 2., 3., 1., 2., 3., 4., 4., 3., 2., 3., 3., 2., 3., 2.],\n",
      "        [2., 3., 2., 3., 1., 0., 1., 2., 4., 3., 2., 3., 5., 4., 3., 2.],\n",
      "        [2., 3., 2., 3., 1., 2., 3., 2., 2., 3., 4., 3., 3., 2., 1., 0.],\n",
      "        [2., 3., 4., 5., 3., 4., 3., 4., 2., 3., 4., 3., 3., 2., 1., 2.],\n",
      "        [2., 3., 4., 5., 3., 4., 3., 2., 2., 3., 2., 1., 5., 4., 3., 2.],\n",
      "        [2., 1., 2., 3., 3., 2., 1., 2., 4., 3., 2., 1., 3., 2., 1., 0.],\n",
      "        [0., 1., 2., 3., 3., 4., 3., 2., 4., 3., 4., 3., 3., 2., 1., 2.],\n",
      "        [2., 3., 2., 3., 3., 4., 3., 4., 4., 3., 2., 3., 3., 4., 3., 2.],\n",
      "        [2., 1., 2., 3., 3., 4., 3., 2., 2., 1., 2., 3., 3., 2., 1., 0.],\n",
      "        [2., 3., 4., 3., 1., 2., 1., 2., 2., 1., 2., 3., 3., 2., 3., 2.],\n",
      "        [2., 3., 2., 3., 1., 2., 3., 2., 2., 1., 0., 1., 3., 2., 1., 0.],\n",
      "        [2., 3., 4., 5., 1., 2., 3., 4., 4., 3., 4., 3., 3., 4., 3., 2.],\n",
      "        [2., 3., 4., 3., 3., 2., 3., 4., 2., 3., 2., 1., 5., 4., 3., 2.],\n",
      "        [2., 3., 4., 5., 1., 2., 1., 2., 4., 3., 4., 3., 3., 2., 1., 0.],\n",
      "        [2., 3., 4., 3., 3., 2., 3., 2., 4., 5., 4., 3., 5., 4., 3., 2.],\n",
      "        [2., 3., 4., 5., 3., 2., 3., 4., 2., 3., 2., 1., 3., 2., 1., 2.],\n",
      "        [0., 1., 2., 3., 3., 4., 3., 4., 2., 3., 2., 3., 3., 2., 3., 2.]])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for seq, labs in data_module.train_dataloader():\n",
    "    print(seq)\n",
    "    print(labs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30af4a-58b4-43df-9cd0-6a3bc0119636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hparam2",
   "language": "python",
   "name": "hparam2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
